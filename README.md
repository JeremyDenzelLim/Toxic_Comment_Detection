# Toxic Comment Detection

## Introduction
Posting comments on online platforms has become a common way to exercise
oneâ€™s right to freedom of expression in the web. However, this basic
right is currently undermined by some users who post toxic comments that
can be defined as inconsiderate, disrespectful, or preposterous. Such
comments could potentially result in other users to avoid discussing on
online platforms. A subtask of sentiment analysis is toxic comment
classification. In the following project, our group aims to present a
classification model for toxic comments and how our model could be
integrated into online applications for automated moderation.

**Refer to the Project Report for full details on the project.**

## Important Instructions
1) All data used in the project are stored in the Data Folder.

2) Codes are saved as ipynb and HTML format. For ease of viewing without opening jupyter notebook, you can open the HTML file instead.

3) Glove Embedding and Google Word2Vec is not included as the file size is too large. You can download it at 
https://nlp.stanford.edu/projects/glove/  
https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit

4) For full explanation on output and analysis of code and results, please refer to the report instead.

5) A short video is also attached to demo how our telegram bot works.

6) Project Presentation can be viewed here as well: 
https://docs.google.com/presentation/d/1EzpzLbPoL5MshRc0AF39qc55K7nkMzgJUPaFm7KuPBY/edit?usp=sharing

7. Please generate and insert your own Telegram Bot Token in the
   Telegram Bot Code

